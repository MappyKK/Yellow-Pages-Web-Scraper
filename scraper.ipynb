{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b9e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Bypass 300 status errors\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Referer\": \"https://www.google.com/\"\n",
    "}\n",
    "\n",
    "\n",
    "BASE_URL = \"https://www.saudiayp.com/\" # change here\n",
    "START_PATH = \"/category/estate_agents\" # change here\n",
    "\n",
    "def get_profile_details(profile_url):\n",
    "    try:\n",
    "        res = requests.get(profile_url, headers=HEADERS)\n",
    "        print(res)\n",
    "        soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "\n",
    "        web_block = soup.find(\"div\", class_=\"text weblinks\")\n",
    "        print(web_block)\n",
    "        if web_block:\n",
    "            link_tag = web_block.find(\"a\")\n",
    "            link = link_tag.get_text(strip=True) if link_tag else None\n",
    "            return link\n",
    "\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching profile: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def get_page_data(url):\n",
    "    page = requests.get(url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    agents = []\n",
    "    print(page)\n",
    "\n",
    "    agent_blocks = soup.find_all(\"div\", class_=\"company with_img g_0\") # Change here for more data company with_img g_0 to company g_0\n",
    "    print(agent_blocks)\n",
    "    for block in agent_blocks:\n",
    "        name_div = block.find(\"div\", class_=\"company_header\")\n",
    "        name_tag = name_div.find(\"a\") if name_div else None\n",
    "        name = name_tag.get_text(strip=True) if name_tag else None\n",
    "        profile_link = BASE_URL + name_tag['href'] if name_tag and name_tag.has_attr('href') else None\n",
    "\n",
    "        address_tag = block.find(\"div\", class_=\"address\")\n",
    "        tagline_tag = block.find(\"div\", class_=\"tagline\")\n",
    "        rating_tag = block.find(\"div\", class_=\"rate\")\n",
    "\n",
    "        # Extract phone and establishment\n",
    "        phone = None\n",
    "        established = None\n",
    "        info_blocks = block.find_all(\"div\", class_=\"s\")\n",
    "        for info in info_blocks:\n",
    "            icon = info.find(\"i\")\n",
    "            if icon:\n",
    "                label = icon.get(\"aria-label\")\n",
    "                span = info.find(\"span\")\n",
    "                if label == \"Phone\" and span:\n",
    "                    phone = span.get_text(strip=True)\n",
    "                elif label == \"Calendar\" and span:\n",
    "                    established = span.get_text(strip=True).replace(\"Established\", \"\").strip()\n",
    "\n",
    "        # Verified status\n",
    "        verified_tag = block.find(\"u\", class_=\"v\")\n",
    "        is_verified = False\n",
    "        if verified_tag and \"Verified\" in verified_tag.get_text(strip=True):\n",
    "            is_verified = True\n",
    "\n",
    "        # Manager name from profile page\n",
    "        website = get_profile_details(profile_link) if profile_link else (None, None)\n",
    "\n",
    "        time.sleep(0.5)  # Be polite to the server\n",
    "\n",
    "        agent = {\n",
    "            \"Name\": name,\n",
    "            \"Profile Link\": profile_link,\n",
    "            \"Website\": website,\n",
    "            \"Address\": address_tag.get_text(strip=True) if address_tag else None,\n",
    "            \"Description\": tagline_tag.get_text(strip=True) if tagline_tag else None,\n",
    "            \"Phone\": phone,\n",
    "            \"Established\": established,\n",
    "            \"Rating\": rating_tag.get_text(strip=True) if rating_tag else None,\n",
    "            \"Verified\": is_verified\n",
    "        }\n",
    "\n",
    "        agents.append(agent)\n",
    "\n",
    "    return agents\n",
    "\n",
    "# Loop through pages\n",
    "all_agents = []\n",
    "for page_num in range(1, 4):  # Scraped the first 3 pages for best quality\n",
    "    if page_num == 1:\n",
    "        url = f\"{BASE_URL}{START_PATH}\"\n",
    "    else:\n",
    "        url = f\"{BASE_URL}/category/estate_agents/{page_num}\" # change here could be of the form of Estate_agents, estate-agents or Estate-agents \n",
    "    print(f\"Scraping page {page_num}: {url}\")\n",
    "    all_agents.extend(get_page_data(url))\n",
    "\n",
    "# Save to JSON\n",
    "with open(\"saudi_top_real_estate_companies.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_agents, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Scraped {len(all_agents)} agents across pages.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
